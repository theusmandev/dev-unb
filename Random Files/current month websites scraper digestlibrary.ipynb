{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOc8TzuWgdwkV6ayf2rPOcm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","import os\n","import random\n","from datetime import datetime\n","from google.colab import drive\n","\n","# üöÄ Mount Google Drive (force remount if already mounted)\n","drive.mount('/content/drive', force_remount=True)\n","\n","# üìå File paths\n","SAVE_PATH_XLSX = \"/content/drive/My Drive/Blogger_Novels_Latest.xlsx\"\n","FAILED_LINKS_FILE = \"/content/drive/My Drive/failed_links.txt\"\n","\n","# üõ° Headers\n","HEADERS = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\"}\n","session = requests.Session()\n","session.headers.update(HEADERS)\n","\n","# üîπ Step 0: Detect current/latest month\n","today = datetime.today()\n","YEAR = today.year\n","MONTH = today.month\n","BLOG_ARCHIVE_URL = f\"https://digestlibrary.com/{YEAR}/{MONTH:02d}/\"\n","\n","print(f\"Fetching posts from: {BLOG_ARCHIVE_URL}\")\n","\n","# üîπ Step 1: Get all post URLs for the latest month\n","response = session.get(BLOG_ARCHIVE_URL)\n","if response.status_code != 200:\n","    print(\"‚ùå Failed to fetch archive page.\")\n","    exit()\n","\n","soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","# Collect all links containing year/month (Blogger-style URLs)\n","post_links = []\n","for a_tag in soup.find_all(\"a\", href=True):\n","    href = a_tag['href']\n","    if f\"/{YEAR}/{MONTH:02d}/\" in href and href not in post_links:\n","        post_links.append(href)\n","\n","print(f\"‚úÖ Found {len(post_links)} posts for latest month.\")\n","\n","# üîπ Step 2: Function to scrape each post\n","def scrape_post(post_url):\n","    retries = 3\n","    for attempt in range(retries):\n","        try:\n","            response = session.get(post_url, timeout=30)\n","            if response.status_code != 200:\n","                time.sleep(3)\n","                continue\n","\n","            soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","            # Title\n","            title_tag = soup.find(\"h1\") or soup.find(\"h2\") or soup.find(\"h3\")\n","            title = title_tag.text.strip() if title_tag else \"No Title Found\"\n","\n","            # Download links\n","            all_links = [a[\"href\"] for a in soup.find_all(\"a\", href=True)]\n","            google_drive_links = [l for l in all_links if \"drive.google\" in l]\n","            mediafire_links = [l for l in all_links if \"mediafire\" in l]\n","\n","            return {\n","                \"Title\": title,\n","                \"URL\": post_url,\n","                \"Google Drive Links\": \", \".join(google_drive_links) if google_drive_links else \"No Google Drive Link\",\n","                \"Mediafire Links\": \", \".join(mediafire_links) if mediafire_links else \"No Mediafire Link\"\n","            }\n","\n","        except Exception as e:\n","            print(f\"‚ö† Attempt {attempt+1} failed for {post_url}: {e}\")\n","            time.sleep(3)\n","\n","    # Save failed link\n","    with open(FAILED_LINKS_FILE, \"a\") as f:\n","        f.write(post_url + \"\\n\")\n","    return None\n","\n","# üîπ Step 3: Scrape all posts\n","novels_data = []\n","for idx, link in enumerate(post_links, start=1):\n","    result = scrape_post(link)\n","    if result:\n","        novels_data.append(result)\n","    print(f\"Scraped {idx}/{len(post_links)}: {link}\")\n","    time.sleep(random.uniform(1, 2))  # Random delay\n","\n","# üîπ Step 4: Save to Excel\n","if novels_data:\n","    df = pd.DataFrame(novels_data)\n","    if os.path.exists(SAVE_PATH_XLSX):\n","        existing_df = pd.read_excel(SAVE_PATH_XLSX, engine='openpyxl')\n","        df = pd.concat([existing_df, df], ignore_index=True)\n","    df.to_excel(SAVE_PATH_XLSX, index=False, engine='openpyxl')\n","\n","print(f\"‚úÖ Scraping complete! Data saved in '{SAVE_PATH_XLSX}'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CNqQxzyk2LSH","executionInfo":{"status":"ok","timestamp":1766487611902,"user_tz":-300,"elapsed":254646,"user":{"displayName":"Devurdunovelbank","userId":"02511973306613964362"}},"outputId":"931fa7a0-1c4d-4c3f-f68a-92531bea3163"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Fetching posts from: https://digestlibrary.com/2025/12/\n","‚úÖ Found 53 posts for latest month.\n","Scraped 1/53: https://digestlibrary.com/2025/12/23/barkha-bahar-by-uzma-bukhari/\n","Scraped 2/53: https://digestlibrary.com/2025/12/23/poonam-rat-aur-chokor-by-asia-mirza/\n","Scraped 3/53: https://digestlibrary.com/2025/12/23/aey-wattan-tere-leye-by-haya-bukhari/\n","Scraped 4/53: https://digestlibrary.com/2025/12/23/hina-digest-october-2018-complete-pdf/\n","Scraped 5/53: https://digestlibrary.com/2025/12/23/shua-digest-april-2016-complete-pdf/\n","Scraped 6/53: https://digestlibrary.com/2025/12/23/bus-kuch-be-khabar-they-by-nosheen-naz-akhtar/\n","Scraped 7/53: https://digestlibrary.com/2025/12/22/naama-bar-hai-bahar-ka-by-sadaf-asif/\n","Scraped 8/53: https://digestlibrary.com/2025/12/22/tishnagi-by-lubna-tahir/\n","Scraped 9/53: https://digestlibrary.com/2025/12/22/tere-ishq-nachaya-complete-by-sidra-ijaz/\n","Scraped 10/53: https://digestlibrary.com/2025/12/22/meri-maa-by-sadia-hameed-chaudhary/\n","Scraped 11/53: https://digestlibrary.com/2025/12/22/roshani-hai-rasta-by-aneeza-syed/\n","Scraped 12/53: https://digestlibrary.com/2025/12/21/ashak-e-nadamat-by-haya-bukhari/\n","Scraped 13/53: https://digestlibrary.com/2025/12/21/shua-digest-december-2016-complete-pdf/\n","Scraped 14/53: https://digestlibrary.com/2025/12/21/shua-digest-june-2016-complete-pdf/\n","Scraped 15/53: https://digestlibrary.com/2025/12/21/shua-digest-march-2016-complete-pdf/\n","Scraped 16/53: https://digestlibrary.com/2025/12/21/shua-digest-august-2016-complete-pdf/\n","Scraped 17/53: https://digestlibrary.com/2025/12/21/shua-digest-november-2016-complete-pdf/\n","Scraped 18/53: https://digestlibrary.com/2025/12/21/shua-digest-october-2016-complete-pdf/\n","Scraped 19/53: https://digestlibrary.com/2025/12/21/shua-digest-may-2016-complete-pdf/\n","Scraped 20/53: https://digestlibrary.com/2025/12/21/kahani-to-badal-gaye-hai-by-nosheen-naz-akhtar/\n","Scraped 21/53: https://digestlibrary.com/2025/12/21/ye-rishta-by-roheela-khan/\n","Scraped 22/53: https://digestlibrary.com/2025/12/21/dair-aayed-darust-aayed-by-uzma-bukhari/\n","Scraped 23/53: https://digestlibrary.com/2025/12/20/ek-naye-mohabbat-by-haya-bukhari/\n","Scraped 24/53: https://digestlibrary.com/2025/12/20/khwateen-digest-january-2015-complete-pdf/\n","Scraped 25/53: https://digestlibrary.com/2025/12/20/kitni-sadiyan-band-hain-by-faiza-iftikhar/\n","Scraped 26/53: https://digestlibrary.com/2025/12/20/youn-to-hona-tha-by-roheela-khan/\n","Scraped 27/53: https://digestlibrary.com/2025/12/20/faisla-by-uzma-bukhari/\n","Scraped 28/53: https://digestlibrary.com/2025/12/20/mohabbat-youn-chupao-na-by-durr-e-suman/\n","Scraped 29/53: https://digestlibrary.com/2025/12/20/pas-e-bahar-khile-by-fatima-zuhra-jabeen/\n","Scraped 30/53: https://digestlibrary.com/2025/12/20/khwateen-digest-october-2005-complete-pdf/\n","Scraped 31/53: https://digestlibrary.com/2025/12/20/khwateen-digest-january-2005-complete-pdf/\n","Scraped 32/53: https://digestlibrary.com/2025/12/20/khwateen-digest-june-2005-complete-pdf/\n","Scraped 33/53: https://digestlibrary.com/2025/12/20/khwateen-digest-february-2010-complete-pdf/\n","Scraped 34/53: https://digestlibrary.com/2025/12/20/khwateen-digest-may-2005-complete-pdf/\n","Scraped 35/53: https://digestlibrary.com/2025/12/19/khwateen-digest-march-2005-complete-pdf/\n","Scraped 36/53: https://digestlibrary.com/2025/12/19/khwateen-digest-march-2012-complete-pdf/\n","Scraped 37/53: https://digestlibrary.com/2025/12/19/ye-umar-bhar-ki-musaften-by-saira-arif/\n","Scraped 38/53: https://digestlibrary.com/2025/12/19/moamma-by-shahida-tallat/\n","Scraped 39/53: https://digestlibrary.com/2025/12/19/fasle-darmiyan-by-sadia-abid/\n","Scraped 40/53: https://digestlibrary.com/2025/12/19/baid-by-sumaira-hameed/\n","Scraped 41/53: https://digestlibrary.com/2025/12/18/shua-digest-november-2015-complete-pdf/\n","Scraped 42/53: https://digestlibrary.com/2025/12/18/dil-aur-dard-by-samra-bukhari/\n","Scraped 43/53: https://digestlibrary.com/2025/12/18/mere-asman-ka-tara-by-naseem-sehar-quraishi/\n","Scraped 44/53: https://digestlibrary.com/2025/12/18/khwateen-digest-october-2011-complete-pdf/\n","Scraped 45/53: https://digestlibrary.com/2025/12/18/khwateen-digest-november-2011-complete-pdf/\n","Scraped 46/53: https://digestlibrary.com/2025/12/18/khwateen-digest-december-2011-complete-pdf/\n","Scraped 47/53: https://digestlibrary.com/2025/12/18/facebook-dot-com-by-fakhra-jabeen/\n","Scraped 48/53: https://digestlibrary.com/2025/12/18/chah-aur-moh-ka-phanda-by-shaheen-malik/\n","Scraped 49/53: https://digestlibrary.com/2025/12/18/rasta-nahi-milta-by-seema-kamal-soofi/\n","Scraped 50/53: https://digestlibrary.com/2025/12/18/dair-na-ho-jaye-by-nuzhat-shabana-haidar/\n","Scraped 51/53: https://digestlibrary.com/2025/12/page/2/\n","Scraped 52/53: https://digestlibrary.com/2025/12/page/3/\n","Scraped 53/53: https://digestlibrary.com/2025/12/page/4/\n","‚úÖ Scraping complete! Data saved in '/content/drive/My Drive/Blogger_Novels_Latest.xlsx'\n"]}]},{"cell_type":"markdown","source":["using sitemap"],"metadata":{"id":"sAFizhx1zwOR"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","import xml.etree.ElementTree as ET\n","import os\n","import concurrent.futures\n","import random\n","import re\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# üåê SITE URL (ONLY THIS)\n","SITE_URL = \"https://digestlibrary.com/\"\n","SITEMAP_URL = SITE_URL.rstrip(\"/\") + \"/post-sitemap.xml\"\n","\n","# üìÅ FILE PATHS\n","SAVE_PATH_XLSX = \"/content/drive/My Drive/DigestLibrary_LatestMonth.xlsx\"\n","FAILED_LINKS_FILE = \"/content/drive/My Drive/failed_links.txt\"\n","\n","# üõ° HEADERS\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n","}\n","session = requests.Session()\n","session.headers.update(HEADERS)\n","\n","# üì• LOAD SITEMAP\n","response = session.get(SITEMAP_URL)\n","if response.status_code != 200:\n","    print(\"‚ùå Sitemap load failed\")\n","    exit()\n","\n","root = ET.fromstring(response.content)\n","all_urls = [\n","    elem.text for elem in root.findall(\".//{http://www.sitemaps.org/schemas/sitemap/0.9}loc\")\n","]\n","\n","print(f\"üîó Total posts found: {len(all_urls)}\")\n","\n","# üìÖ DETECT LATEST MONTH FROM LAST POST\n","last_post_url = all_urls[-1]\n","print(\"üß† Last Post URL:\", last_post_url)\n","\n","match = re.search(r\"/(\\d{4})/(\\d{2})/\", last_post_url)\n","if not match:\n","    print(\"‚ùå Date not found in last URL\")\n","    exit()\n","\n","YEAR, MONTH = match.group(1), match.group(2)\n","print(f\"üìÖ Latest month detected: {YEAR}/{MONTH}\")\n","\n","# üéØ FILTER POSTS OF LATEST MONTH\n","post_urls = [\n","    url for url in all_urls\n","    if f\"/{YEAR}/{MONTH}/\" in url\n","]\n","\n","print(f\"‚úÖ Posts in latest month: {len(post_urls)}\")\n","\n","# üîé ROBUST TITLE EXTRACTOR\n","def extract_title(soup):\n","    selectors = [\n","        \"h1.post-title\",\n","        \"h1.entry-title\",\n","        \"h1.post-title.entry-title\",\n","\n","        \"h2.post-title\",\n","        \"h2.entry-title\",\n","\n","        \"h3.post-title\",\n","        \"h3.entry-title\",\n","\n","        \"article h1\",\n","        \"article h2\",\n","        \"article h3\"\n","    ]\n","\n","    for selector in selectors:\n","        tag = soup.select_one(selector)\n","        if tag:\n","            title = tag.get_text(strip=True)\n","            if title and title.lower() not in [\"digest library\"]:\n","                return title\n","\n","    meta = soup.find(\"meta\", property=\"og:title\")\n","    if meta and meta.get(\"content\"):\n","        clean = meta[\"content\"].replace(\"Digest Library\", \"\")\n","        return clean.strip(\" -|\")\n","\n","    return \"Title Not Found\"\n","\n","# üîç SCRAPE FUNCTION\n","def scrape_post(post_url):\n","    try:\n","        r = session.get(post_url, timeout=30)\n","        if r.status_code != 200:\n","            return None\n","\n","        soup = BeautifulSoup(r.text, \"html.parser\")\n","\n","        title = extract_title(soup)\n","\n","        links = [a[\"href\"] for a in soup.find_all(\"a\", href=True)]\n","        drive_links = [l for l in links if \"drive.google\" in l]\n","        mediafire_links = [l for l in links if \"mediafire\" in l]\n","\n","        return {\n","            \"Title\": title,\n","            \"Post URL\": post_url,\n","            \"Google Drive Links\": \", \".join(drive_links),\n","            \"Mediafire Links\": \", \".join(mediafire_links)\n","        }\n","\n","    except Exception as e:\n","        with open(FAILED_LINKS_FILE, \"a\") as f:\n","            f.write(post_url + \"\\n\")\n","        return None\n","\n","# üöÄ START SCRAPING\n","novels_data = []\n","\n","with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n","    for result in executor.map(scrape_post, post_urls):\n","        if result:\n","            novels_data.append(result)\n","        time.sleep(random.uniform(1, 2))\n","\n","# üíæ SAVE TO EXCEL\n","df = pd.DataFrame(novels_data)\n","df.to_excel(SAVE_PATH_XLSX, index=False)\n","\n","print(\"‚úÖ Scraping completed successfully!\")\n","print(f\"üìÅ File saved at: {SAVE_PATH_XLSX}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdjuuTJ2yXhL","executionInfo":{"status":"ok","timestamp":1766486377361,"user_tz":-300,"elapsed":98248,"user":{"displayName":"Devurdunovelbank","userId":"02511973306613964362"}},"outputId":"036cb0cc-98ed-461c-c9a3-d4f2c8846fb6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","üîó Total posts found: 1001\n","üß† Last Post URL: https://digestlibrary.com/2023/01/14/piyar-ki-khushboo-by-huma-kokab-bukhari/\n","üìÖ Latest month detected: 2023/01\n","‚úÖ Posts in latest month: 55\n","‚úÖ Scraping completed successfully!\n","üìÅ File saved at: /content/drive/My Drive/DigestLibrary_LatestMonth.xlsx\n"]}]}]}