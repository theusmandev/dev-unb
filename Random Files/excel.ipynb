{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNm7hJFAdmvwf+9ZBCdcpAv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"id":"DNnxyD_CnT0x","executionInfo":{"status":"ok","timestamp":1765527188460,"user_tz":-300,"elapsed":68028,"user":{"displayName":"Urdu3","userId":"09220004236797987973"}},"outputId":"b49aae7f-94c2-4692-a730-d02fa10bab0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Authenticating...\n","Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n","WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n"]},{"output_type":"stream","name":"stdout","text":["Target ID: 1NwVjSAo5OFvuK-29RNUXdSGp9L-dVBs6\n","Scanning start... (Sirf PDFs collect ho rahi hain)\n","Folders Scanned: 41 | PDFs Found: 219\n","Scanning Complete! Total PDFs found: 219\n","Excel file taiyar kar raha hun...\n","\n","SUCCESS! Excel file ban gayi hai.\n","Location: /content/drive/MyDrive/Clean_Novel_List.xlsx\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_324de080-8db5-4747-9d7c-581a07397735\", \"Clean_Novel_List.xlsx\", 16018)"]},"metadata":{}}],"source":["# GOOGLE DRIVE PDF TO EXCEL (CLEAN TITLES VERSION)\n","# Target Folder: 1ruT1ZUfgKZb2YIyLtvr7pooygXUnbk-Z\n","\n","import pandas as pd\n","import re  # Text safayi ke liye library\n","from googleapiclient.discovery import build\n","from google.colab import auth, drive, files\n","from google.auth import default\n","\n","# --- CONFIGURATION ---\n","TARGET_FOLDER_ID = \"1NwVjSAo5OFvuK-29RNUXdSGp9L-dVBs6\"\n","OUTPUT_FILENAME = \"Clean_Novel_List.xlsx\"\n","\n","# Step 1: Authentication\n","print(\"Authenticating...\")\n","drive.mount('/content/drive')\n","auth.authenticate_user()\n","creds, _ = default()\n","service = build('drive', 'v3', credentials=creds)\n","\n","print(f\"Target ID: {TARGET_FOLDER_ID}\")\n","print(\"Scanning start... (Sirf PDFs collect ho rahi hain)\")\n","\n","# Step 2: Scanning Logic\n","def scan_folder_recursive(folder_id):\n","    found_items = []\n","    folders_to_process = [folder_id]\n","    processed_count = 0\n","\n","    while folders_to_process:\n","        current_id = folders_to_process.pop(0)\n","\n","        page_token = None\n","        while True:\n","            try:\n","                query = f\"'{current_id}' in parents and trashed = false and (mimeType = 'application/vnd.google-apps.folder' or mimeType = 'application/pdf')\"\n","\n","                results = service.files().list(\n","                    q=query,\n","                    fields=\"nextPageToken, files(id, name, mimeType)\",\n","                    includeItemsFromAllDrives=True,\n","                    supportsAllDrives=True,\n","                    pageSize=1000,\n","                    pageToken=page_token\n","                ).execute()\n","\n","                items = results.get('files', [])\n","\n","                for item in items:\n","                    if item['mimeType'] == 'application/pdf':\n","                        found_items.append(item)\n","                    elif item['mimeType'] == 'application/vnd.google-apps.folder':\n","                        folders_to_process.append(item['id'])\n","\n","                page_token = results.get('nextPageToken')\n","                if not page_token:\n","                    break\n","            except Exception as e:\n","                print(f\"Skipping folder due to error: {e}\")\n","                break\n","\n","        processed_count += 1\n","        print(f\"Folders Scanned: {processed_count} | PDFs Found: {len(found_items)}\", end='\\r')\n","\n","    return found_items\n","\n","# --- EXECUTION ---\n","raw_items = scan_folder_recursive(TARGET_FOLDER_ID)\n","\n","print(f\"\\nScanning Complete! Total PDFs found: {len(raw_items)}\")\n","print(\"Excel file taiyar kar raha hun...\")\n","\n","# Step 3: Data Cleaning & Excel Prep\n","data = []\n","\n","for item in raw_items:\n","    original_name = item['name']\n","    file_id = item['id']\n","\n","    # --- TITLE CLEANING LOGIC START ---\n","\n","    # 1. Sabse pehle .pdf extension hatao (Case insensitive)\n","    clean_title = re.sub(r'\\.pdf$', '', original_name, flags=re.IGNORECASE)\n","\n","    # 2. Specific website branding hatao: (www.urdunovelbanks.com)\n","    # Ye brackets aur uske andar ka text remove karega agar wo specific site hai\n","    clean_title = clean_title.replace('(www.urdunovelbanks.com)', '')\n","\n","    # Optional: Agar aap chahte hain ke KOI BHI website jo brackets ma ho remove ho jaye\n","    # to niche wali line ka # hata den:\n","    # clean_title = re.sub(r'\\(www\\..*?\\)', '', clean_title)\n","\n","    # 3. Extra spaces (shuru aur aakhir ki) saaf karo\n","    clean_title = clean_title.strip()\n","\n","    # --- TITLE CLEANING LOGIC END ---\n","\n","    link = f\"https://drive.google.com/file/d/{file_id}/view\"\n","\n","    data.append({\n","        \"Titles\": clean_title,\n","        \"Links\": link\n","    })\n","\n","# Step 4: Save to Excel\n","if data:\n","    df = pd.DataFrame(data)\n","\n","    output_path = f\"/content/drive/MyDrive/{OUTPUT_FILENAME}\"\n","    df.to_excel(output_path, index=False)\n","\n","    print(f\"\\nSUCCESS! Excel file ban gayi hai.\")\n","    print(f\"Location: {output_path}\")\n","    files.download(output_path)\n","else:\n","    print(\"\\nKoi PDF nahi mili.\")"]}]}